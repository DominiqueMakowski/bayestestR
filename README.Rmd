---
output: 
  github_document:
    toc: false
    fig_width: 10.08
    fig_height: 6
tags: [r, bayesian, posterior, test]
vignette: >
  %\VignetteIndexEntry{README}
  \usepackage[utf8]{inputenc}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

<!-- rmarkdown v1 -->
# bayestestR <img src='man/figures/logo.svg' align="right" height="139" />

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  fig.path = "README-"
)
```


[![Build Status](https://travis-ci.org/DominiqueMakowski/bayestestR.svg?branch=master)](https://travis-ci.org/DominiqueMakowski/bayestestR)
[![codecov](https://codecov.io/gh/DominiqueMakowski/bayestestR/branch/master/graph/badge.svg)](https://codecov.io/gh/DominiqueMakowski/bayestestR)
[![HitCount](http://hits.dwyl.io/DominiqueMakowski/bayestestR.svg)](http://hits.dwyl.io/DominiqueMakowski/bayestestR)
[![Documentation](https://img.shields.io/badge/documentation-bayestestR-orange.svg?colorB=E91E63)](https://neuropsychology.github.io/psycho.R)






```{r eval=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# Create logo
library(ggplot2)
library(dplyr)
library(hexSticker)
library(bayestestR)

set.seed(333)

posterior <- rnorm_perfect(1000, 2, 1)


p <- posterior %>% 
  density() %>% 
  as.data.frame() %>% 
  mutate(fill = ifelse(x > hdi(posterior, 75)[2], "sup", "hdi"),
         fill = ifelse(x < hdi(posterior, 75)[1], "inf", fill),
         fill = ifelse(x < 0, "p", fill)) %>% 
  ggplot(aes(x=x, y=y)) +
  geom_ribbon(aes(ymin=0, ymax=y, fill=fill)) +
  scale_fill_manual(values=c("p"="#E91E63", "inf"="#FF9800", "hdi"="#FFC107", "sup"="#FF9800"), guide=FALSE) +
  geom_vline(xintercept=0, linetype="dotted", size=0.1) +
  # geom_segment(x=map_estimate(posterior)[1], xend=map_estimate(posterior)[1],
  #              y=0, yend=map_estimate(posterior)[2], size=0.25, color="#E91E63") +
  geom_line(size=0.35) +
  theme_void() + 
  theme_transparent() +
  scale_y_continuous(expand = c(0, 0.002))
p

s <- hexSticker::sticker(p, package="bayestestR", 
                    # p_size=8, 
                    s_x=1,
                    # s_y=.75,
                    s_width=1.2, 
                    s_height=0.8,
                    h_fill="#FFC107", 
                    h_color="#E91E63",
                    filename="../logo.svg")
s
```


## Goal

`bayestestR` is a lightweight package providing utilities to describe posterior distributions and Bayesian models.


## Installation


Run the following:

```{r eval=FALSE, message=FALSE, warning=FALSE}
install.packages("devtools")
devtools::install_github("DominiqueMakowski/bayestestR")
```
```{r message=FALSE, warning=FALSE}
library("bayestestR")
```


---

## Functions


### Posterior Description

- **`hdi()`**: Compute the Highest Density Interval (HDI) of a posterior distribution, i.e., the interval which contains all points within the interval have a higher probability density than points outside the interval. The HDI is used in the context of Bayesian posterior characterisation as Credible Interval (CI).

```{r message=FALSE, warning=FALSE, results='hide'}
hdi(posterior = rnorm(1000), CI = 90)
```

- **`map_estimate()`**: Find the Highest Maximum A Posteriori (MAP) estimate of a posterior. It corresponds to the 'peak' of the posterior distribution.

```{r message=FALSE, warning=FALSE, results='hide'}
map_estimate(rnorm(1000, 1, 1))
```

- **`rope()`**: Compute the proportion of the HDI of a posterior distribution that lies within a region of practical equivalence.

```{r message=FALSE, warning=FALSE, results='hide'}
rope(posterior = rnorm(1000, 1, 1), bounds = c(-0.1, 0.1))
```

### Null-Hypothesis Significance Testing (NHST)

- **`rope_test()`**: Perform a Test for Practical Equivalence based on the "HDI+ROPE decision rule" (Kruschke 2018) to check whether parameter values should be accepted or rejected against an explicitely formulated "null hypothesis".

```{r message=FALSE, warning=FALSE, results='hide'}
rope_test(posterior = rnorm(1000, 1, 1), bounds = c(-0.1, 0.1))
```


- **`p_rope()`**: The ROPE-based p-value represents the maximum Credible Interval (HDI) that does not contain (positive values) or is entirely contained (negative values) in the negligible values space defined by the ROPE. A ROPE-based p of 97% means that there is a probability of .97 that a parameter (desccribed by its posterior distribution) is outside the ROPE.

```{r message=FALSE, warning=FALSE, results='hide'}
p_rope(posterior = rnorm(1000, 1, 1), bounds = c(-0.1, 0.1))
```

- **`p_direction()`**: Compute the Probability of Direction (p, also known as the Maximum Probability of Effect - MPE), a Bayesian equivalent of the p-value (altough differently expressed). It varies between 50\% and 100\% and can be interpreted as the probability that a parameter (described by its posterior distribution) is positive or negative (following  the median's sign). It is defined as the proportion of the posterior distribution of the median's sign. It is used as an index of effect existence, i.e., whether the probability that the effect is in the same direction than the point-estimate (independently of the effect's size or significance). This p-value is fairly similar to its frequentist counterpart (i.e., is strongly correlated).

```{r message=FALSE, warning=FALSE, results='hide'}
p_direction(rnorm(1000, mean = 1, sd = 1))
```

- **`p_map()`**: Compute a Bayesian equivalent of the p-value, related to the odds that a parameter (described by its posterior distribution) has againt the null hypothesis (h0) using Mills' (2014, 2017) Objective Bayesian Hypothesis Testing paradigm. It is mathematically based on the density at the Maximum A Priori (MAP).

```{r message=FALSE, warning=FALSE, results='hide'}
p_map(posterior = rnorm(1000, 1, 1))
```

### Utilities

- **`rnorm_perfect()`**: Generate a sample of size n with a near-perfect normal distribution.

```{r message=FALSE, warning=FALSE, results='hide'}
rnorm_perfect(n = 10)
```






## Credits

You can cite the package as following:

- Makowski, (2019). *Understand and Describe Bayesian Models and Posterior Distributions using BayestestR*. CRAN. doi: .


Please remember that parts of the code in this package was inspired / shamelessly copied from other great packages that you must check out and cite, such as [sjstats](https://github.com/strengejacke/sjstats) or [BayesTesting.jl](https://github.com/tszanalytics/BayesTesting.jl). All credits go to their authors.