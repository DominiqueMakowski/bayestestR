<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Bayes Factors • bayestestR</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Bayes Factors">
<meta property="og:description" content="bayestestR">
<meta property="og:image" content="/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-97457476-7"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-97457476-7');
</script>
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">bayestestR</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.8.2</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
<li>
  <a href="../reference/index.html">Features</a>
</li>
<li>
  <a href="../articles/bayestestR.html">Get started</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Examples
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/example1.html">1. Initiation to Bayesian models</a>
    </li>
    <li>
      <a href="../articles/example2.html">2. Confirmation of Bayesian skills</a>
    </li>
    <li>
      <a href="../articles/example3.html">3. Become a Bayesian master</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/credible_interval.html">Credible Intervals (CI)</a>
    </li>
    <li>
      <a href="../articles/region_of_practical_equivalence.html">Region of Practical Equivalence (ROPE)</a>
    </li>
    <li>
      <a href="../articles/probability_of_direction.html">Probability of Direction (pd)</a>
    </li>
    <li>
      <a href="../articles/bayes_factors.html">Bayes Factors (BF)</a>
    </li>
    <li>
      <a href="../articles/indicesEstimationComparison.html">Comparison of Point-Estimates</a>
    </li>
    <li>
      <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2019.02767/full">Comparison of Indices of Effect Existence</a>
    </li>
    <li>
      <a href="../articles/mediation.html">Mediation Analysis: Direct and Indirect Effects</a>
    </li>
  </ul>
</li>
<li>
  <a href="../articles/guidelines.html">Guidelines</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/easystats/bayestestR/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="bayes_factors_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Bayes Factors</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/easystats/bayestestR/blob/master/vignettes/bayes_factors.Rmd"><code>vignettes/bayes_factors.Rmd</code></a></small>
      <div class="hidden name"><code>bayes_factors.Rmd</code></div>

    </div>

    
    
<p>This vignette can be referred to by citing the following:</p>
<ul>
<li>Makowski, D., Ben-Shachar, M. S., &amp; Lüdecke, D. (2019). <em>bayestestR: Describing Effects and their Uncertainty, Existence and Significance within the Bayesian Framework</em>. Journal of Open Source Software, 4(40), 1541. <a href="https://doi.org/10.21105/joss.01541" class="uri">https://doi.org/10.21105/joss.01541</a>
</li>
<li>Makowski, D., Ben-Shachar, M. S., Chen, S. H. A., &amp; Lüdecke, D. (2019). <em>Indices of Effect Existence and Significance in the Bayesian Framework</em>. Retrieved from <a href="https://doi.org/10.3389/fpsyg.2019.02767">10.3389/fpsyg.2019.02767</a>
</li>
</ul>
<hr>
<p>The adoption of the Bayesian framework for applied statistics, especially in the social and psychological sciences, seems to be developing in two distinct directions. One of the key topics marking their separation is their opinion about <strong>the Bayes factor</strong>. In short, some authors (e.g., the “Amsterdam school”, led by <a href="https://www.bayesianspectacles.org/">Wagenmakers</a>) advocate its use and emphasize its qualities as a statistical index, while others point to its limits and prefer, instead, the precise description of posterior distributions (using <a href="https://easystats.github.io/bayestestR/reference/hdi.html">CIs</a>, <a href="https://easystats.github.io/bayestestR/reference/rope.html">ROPEs</a>, etc.).</p>
<p><strong>bayestestR</strong> does not take a side in this debate, rather offering tools to help you in whatever analysis you want to achieve. Instead, it strongly supports the notion of an <em>informed choice:</em> <strong>discover the methods, try them, understand them, learn about them, and decide for yourself</strong>.</p>
<p>Having said that, here’s an introduction to Bayes factors :)</p>
<div id="the-bayes-factor" class="section level1">
<h1 class="hasAnchor">
<a href="#the-bayes-factor" class="anchor"></a>The Bayes Factor</h1>
<p><strong>Bayes factors (BFs) are indices of <em>relative</em> evidence of one “model” over another</strong>, which can be used in the Bayesian framework as alternatives to classical (frequentist) hypothesis testing indices (such as <span class="math inline">\(p-values\)</span>).</p>
<p>According to Bayes’ theorem, we can update prior probabilities of some model <span class="math inline">\(M\)</span> (<span class="math inline">\(P(M)\)</span>) to posterior probabilities (<span class="math inline">\(P(M|D)\)</span>) after observing some datum <span class="math inline">\(D\)</span> by accounting for the probability of observing that datum given the model (<span class="math inline">\(P(D|M)\)</span>, also known as the <em>likelihood</em>):</p>
<p><span class="math display">\[
P(M|D) = \frac{P(D|M)\times P(M)}{P(D)}
\]</span></p>
<p>Using this equation, We can compare the probability-odds of two models:</p>
<p><span class="math display">\[
\underbrace{\frac{P(M_1|D)}{P(M_2|D)}}_{\text{Posterior Odds}} = 
\underbrace{\frac{P(D|M_1)}{P(D|M_2)}}_{\text{Likelihood Ratio}} 
\times
\underbrace{\frac{P(M_1)}{P(M_2)}}_{\text{Prior Odds}}
\]</span> Where the <em>likelihood ratio</em> (the middle term) is the <em>Bayes factor</em>:</p>
<p><span class="math display">\[
BF_{12}=\frac{P(D|M_1)}{P(D|M_2)}
\]</span></p>
<p>Thus, Bayes factors can be seen either as a ratio quantifying <strong><em>the relative probability of some observed data by two models</em></strong> as they can be computed by comparing the marginal likelihoods of the two models, or as <strong><em>the degree by which some prior beliefs about the relative credibility of two models are to be updated</em></strong> as they can be computed by dividing posterior odds by prior odds, as we will soon demonstrate.</p>
<p>Here we provide functions for computing Bayes factors in two different applications: <strong>testing single parameters (coefficients) within a model</strong> and <strong>comparing statistical models themselves</strong>.</p>
<div id="bayesfactor_parameters" class="section level2">
<h2 class="hasAnchor">
<a href="#bayesfactor_parameters" class="anchor"></a>Testing Models’ Parameters with Bayes Factors</h2>
<p>A <strong><em>Bayes factor for a single parameter</em></strong> can be used to answer the question:</p>
<blockquote>
<p><strong>Given the observed data, has the null hypothesis of an absence of an effect become more, or less credible?</strong></p>
</blockquote>
<div class="figure" style="text-align: center">
<img src="https://github.com/easystats/easystats/raw/master/man/figures/bayestestR/deathsticks.jpg" alt="Bayesian analysis of the Students' (1908) Sleep data set." width="80%"><p class="caption">
Bayesian analysis of the Students’ (1908) Sleep data set.
</p>
</div>
<p>Let’s use the Students’ (1908) Sleep data set (<code><a href="https://rdrr.io/r/utils/data.html">data("sleep")</a></code>), in which <strong>people took some drug</strong> and where the researchers measured the <strong>extra hours of sleep</strong> that they slept afterwards. We will try answering the following question:</p>
<p><em>given the observed data, has the hypothesis that the drug (the effect of <code>group</code>) <strong>has no effect</strong> on the numbers of hours of <strong>extra sleep</strong> (variable <code>extra</code>) become more of less credible?</em></p>
<p><img src="bayes_factors_files/figure-html/sleep_boxplot-1.png" width="1093.75"></p>
<p>The <strong>bloxplot</strong> suggests that the second group has a higher number of hours of extra sleep. <em>By how much?</em> Let’s fit a simple <a href="https://easystats.github.io/bayestestR/articles/example1.html">Bayesian linear model</a>, with a prior of <span class="math inline">\(b_{group} \sim N(0, 3)\)</span>:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mc-stan.org/rstanarm/">rstanarm</a></span><span class="op">)</span>

<span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span><span class="op">(</span><span class="va">extra</span> <span class="op">~</span> <span class="va">group</span>, data <span class="op">=</span> <span class="va">sleep</span>,
                  prior <span class="op">=</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/priors.html">normal</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">3</span>, autoscale <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div id="testing-against-a-null-region" class="section level3">
<h3 class="hasAnchor">
<a href="#testing-against-a-null-region" class="anchor"></a>Testing against a null-<em>region</em>
</h3>
<p>One way of operationlizing the null-hypothesis is by setting a null region, such that an effect that falls within this interval would be practically equivalent to the null <span class="citation">(Kruschke, 2010)</span>. In our case, that means defining a range of effects we would consider equal to the drug having no effect at all. We can then compute the prior probability of the drug’s effect falling <em>within this null-region</em>, and the prior probability of the drug’s effect falling <em>outside the null-region</em> to get our <em>prior odds</em>. Say any effect smaller than an hour of extra sleep is practically equivalent to being no effect at all, we would define our prior odds as:</p>
<p><span class="math display">\[
\frac
{P(b_{drug} \in [-1, 1])}
{P(b_{drug} \notin [-1, 1])}
\]</span></p>
<p>Given our prior has a normal distribution centered at 0 hours with a scale (an SD) of 2.5 hours, our priors would look like this:</p>
<p><img src="bayes_factors_files/figure-html/unnamed-chunk-2-1.png" width="1093.75"></p>
<p>and the prior odds would be 2.2.</p>
<p>By looking at the posterior distribution, can now compute the posterior probability of the drug’s effect falling <em>within the null-region</em>, and the posterior probability of the drug’s effect falling <em>outside the null-region</em> to get our <em>posterior odds</em>:</p>
<p><span class="math display">\[
\frac
{P(b_{drug} \in [-1,1] | Data)}
{P(b_{drug} \notin [-1,1] | Data)}
\]</span></p>
<p><img src="bayes_factors_files/figure-html/rstanarm_fit-1.png" width="1093.75"></p>
<p>We can see that the center of the posterior distribution has shifted away from 0 (to ~1.5). Likewise, the posterior odds are 2 - which seems to favor <strong>the effect being non-null</strong>, but… <em>does this mean the data support the alternative over the null?</em> Hard to say, since even before the data were observed, the priors already favored the alternative - so we need to take our priors into account here!</p>
<p>Let’s compute the Bayes factor as the change from the prior odds to the posterior odds: <span class="math inline">\(BF_{10} = Odds_{posterior} / Odds_{prior} = 0.9\)</span>! This BF indicates that the data provide 1/0.9 = 1.1 times more evidence for the effect of the drug being practically nothing than it does for the drug having some clinically significant effect. Thus, although the center of distribution has shifted away from 0, and the posterior distribution seems to favor a non-null effect of the drug, it seems that given the observed data, the probability mass has <em>overall</em> shifted closer to the null interval, making the values in the null interval more probable! <span class="citation">(see <em>Non-overlapping Hypotheses</em> in Morey &amp; Rouder, 2011)</span></p>
<p>All of this can be achieved with the function <code><a href="../reference/bayesfactor_parameters.html">bayesfactor_parameters()</a></code>, which computes a Bayes factor for each of the model’s parameters:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">My_first_BF</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bayesfactor_parameters.html">bayesfactor_parameters</a></span><span class="op">(</span><span class="va">model</span>, null <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
<span class="va">My_first_BF</span></code></pre></div>
<pre><code>&gt; # Bayes Factor (Null-Interval)
&gt; 
&gt; Parameter   |    BF
&gt; -------------------
&gt; (Intercept) | 0.098
&gt; group2      | 0.888
&gt; 
&gt; * Evidence Against The Null: [-1, 1]</code></pre>
<p>We can also plot using the <code>see</code> package:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://easystats.github.io/see/">see</a></span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">My_first_BF</span><span class="op">)</span></code></pre></div>
<p><img src="bayes_factors_files/figure-html/unnamed-chunk-5-1.png" width="1093.75"></p>
<p>Note that <strong>interpretation guides</strong> for Bayes factors can be found in the <code>effectsize</code> package:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">effectsize</span><span class="fu">::</span><span class="fu"><a href="https://easystats.github.io/effectsize/reference/interpret_bf.html">interpret_bf</a></span><span class="op">(</span><span class="va">My_first_BF</span><span class="op">$</span><span class="va">BF</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, include_value <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
<pre><code>&gt; [1] "anecdotal evidence (BF = 1/1.13) against"
&gt; (Rules: jeffreys1961)</code></pre>
</div>
<div id="testing-against-the-point-null-0" class="section level3">
<h3 class="hasAnchor">
<a href="#testing-against-the-point-null-0" class="anchor"></a>Testing against the <em>point</em>-null (0)</h3>
<p><strong>What if we don’t know what region would be practically equivalent to 0?</strong> Or if we just want the null to be exactly zero? Not a problem - as the width of null region shrinks to a point, the change from the prior probability to the posterior probability of the null can be estimated by comparing the density of the null value between the two distributions.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> This ratio is called the <strong>Savage-Dickey ratio</strong>, and has the added benefit of also being an approximation of a Bayes factor comparing the estimated model against the a model in which the parameter of interest has been restricted to a point-null:</p>
<blockquote>
<p>“[…] the Bayes factor for <span class="math inline">\(H_0\)</span> versus <span class="math inline">\(H_1\)</span> could be obtained by analytically integrating out the model parameter <span class="math inline">\(\theta\)</span>. However, the Bayes factor may likewise be obtained by only considering <span class="math inline">\(H_1\)</span>, and dividing the height of the posterior for <span class="math inline">\(\theta\)</span> by the height of the prior for <span class="math inline">\(\theta\)</span>, at the point of interest.” <span class="citation">(Wagenmakers, Lodewyckx, Kuriyal, &amp; Grasman, 2010)</span></p>
</blockquote>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">My_second_BF</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bayesfactor_parameters.html">bayesfactor_parameters</a></span><span class="op">(</span><span class="va">model</span>, null <span class="op">=</span> <span class="fl">0</span><span class="op">)</span>
<span class="va">My_second_BF</span></code></pre></div>
<pre><code>&gt; # Bayes Factor (Savage-Dickey density ratio)
&gt; 
&gt; Parameter |    BF
&gt; -----------------
&gt; group2    | 1.264
&gt; 
&gt; * Evidence Against The Null: [0]</code></pre>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">My_second_BF</span><span class="op">)</span></code></pre></div>
<p><img src="bayes_factors_files/figure-html/unnamed-chunk-9-1.png" width="1093.75"></p>
</div>
<div id="directional-hypotheses" class="section level3">
<h3 class="hasAnchor">
<a href="#directional-hypotheses" class="anchor"></a>Directional hypotheses</h3>
<p>We can also compute Bayes factors for directional hypotheses (“one sided”), if we have a prior hypotheses about the direction of the effect. This can be done by setting an <em>order restriction</em> on the prior distribution (which results in an order restriction on the posterior distribution) of the alternative <span class="citation">(Morey &amp; Wagenmakers, 2014)</span>. For example, if we have a prior hypothesis that <em>the drug has a positive effect on the number of sleep hours</em>, the alternative will be restricted to the region to the right of the null (point or interval):</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">test_group2_right</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bayesfactor_parameters.html">bayesfactor_parameters</a></span><span class="op">(</span><span class="va">model</span>, direction <span class="op">=</span> <span class="st">"&gt;"</span><span class="op">)</span>
<span class="va">test_group2_right</span></code></pre></div>
<pre><code>&gt; # Bayes Factor (Savage-Dickey density ratio)
&gt; 
&gt; Parameter |    BF
&gt; -----------------
&gt; group2    | 2.422
&gt; 
&gt; * Evidence Against The Null: [0]
&gt; *                 Direction: Right-Sided test</code></pre>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">test_group2_right</span><span class="op">)</span></code></pre></div>
<p><img src="bayes_factors_files/figure-html/unnamed-chunk-10-1.png" width="1093.75"></p>
<p>As we can see, given that we have an <em>a priori</em> assumption about the direction of the effect (that the effect is positive), <strong>the presence of an effect is 2.8 times more likely than the absence of an effect</strong>, given the observed data (or that the data are 2.8 time more probable under <span class="math inline">\(H_1\)</span> than <span class="math inline">\(H_0\)</span>). This indicates that, given the observed data, and a priori hypothesis, the posterior mass has shifted away from the null value, giving some evidence against the null (note that a Bayes factor of 2.8 is still considered quite <a href="https://easystats.github.io/effectsize/reference/interpret_bf.html">weak evidence</a>).</p>
<p>Thank to the flexibility of Bayesian statistics, it is also possible to compute a Bayes factor for <strong>dividing</strong> hypotheses - that is, for a null and alternative that are <em>complementary</em>, opposing one-sided hypotheses <span class="citation">(Morey &amp; Wagenmakers, 2014)</span>. For example, above we compared an alternative of <span class="math inline">\(H_A\)</span>: <em>the drug has a positive effects</em> to the null <span class="math inline">\(H_0\)</span>: <em>the drug has no effect</em>, as we did above. But we can also compare instead the same alternative to its <em>complementary</em> hypothesis: <span class="math inline">\(H_{-A}\)</span>: <em>the drug has a negative effects</em>.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">test_group2_dividing</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bayesfactor_parameters.html">bayesfactor_parameters</a></span><span class="op">(</span><span class="va">model</span>, null <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="cn">Inf</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span>
<span class="va">test_group2_dividing</span></code></pre></div>
<pre><code>&gt; # Bayes Factor (Null-Interval)
&gt; 
&gt; Parameter |     BF
&gt; ------------------
&gt; group2    | 20.745
&gt; 
&gt; * Evidence Against The Null: [-Inf, 0]</code></pre>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">test_group2_dividing</span><span class="op">)</span></code></pre></div>
<p><img src="bayes_factors_files/figure-html/unnamed-chunk-11-1.png" width="1093.75"></p>
<p>We can see that this test produces even stronger (more conclusive) evidence than the one-sided vs. point-null test! And indeed, as a rule of thumb, the more specific the two hypotheses are, and the more distinct they are from one another, the more “power” our Bayes factor has!<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p>Thanks to the transitivity of Bayes factors, we can also use <code><a href="../reference/bayesfactor_parameters.html">bayesfactor_parameters()</a></code> to compare even more types of hypotheses, with some trickery. For example:</p>
<p><span class="math display">\[
\underbrace{BF_{0&lt;b&lt;1\text{ vs. }b=0}}_{\text{range vs. point}}
= 
\underbrace{BF_{b&lt;0\text{ vs. }b=0}}_{\text{directional vs. point}} 
/
\underbrace{BF_{b&lt;0\text{ vs. }0&lt;b&lt;1}}_{\text{directional vs. range}} 
\]</span> <strong>NOTE</strong>: See the <em>Testing Contrasts</em> appendix below.</p>
</div>
<div id="si" class="section level3">
<h3 class="hasAnchor">
<a href="#si" class="anchor"></a>Support intervals</h3>
<p>So far we’ve seen that Bayes factors quantify relative support between competing hypotheses. However, we can also ask:</p>
<blockquote>
<p><strong>Upon observing the data, the credibility of which of the parameter’s values has increased (or decreased)?</strong></p>
</blockquote>
<p>For example, we’ve seen that the point null has become somewhat less credible after observing the data, but we might also ask <em>which values have gained some credibility given the observed data?</em>. The resulting range of values is called <strong>the support interval</strong> as it indicates which values are supported by the data <span class="citation">(Wagenmakers, Gronau, Dablander, &amp; Etz, 2018)</span>. We can do this by once again comparing the prior and posterior distributions and checking where the posterior densities are higher than the prior densities. This can be achieved with the <code><a href="../reference/si.html">si()</a></code> function:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">my_first_si</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/si.html">si</a></span><span class="op">(</span><span class="va">model</span>, BF <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
<span class="va">my_first_si</span></code></pre></div>
<pre><code>&gt; # Support Interval
&gt; 
&gt; Parameter |    BF = 1 SI
&gt; ------------------------
&gt; group2    | [0.15, 3.04]</code></pre>
<p>The argument <code>BF = 1</code> indicates that we want the interval to contain values that have gained support by a factor of at least 1 (that is, any support at all).</p>
<p>Visually, we can see that the credibility of all the values within this interval has increased (and likewise the credibility of all the values outside this interval has decreased):</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">my_first_si</span><span class="op">)</span></code></pre></div>
<p><img src="bayes_factors_files/figure-html/unnamed-chunk-14-1.png" width="1093.75"></p>
<p>We can also see the this support interval (just barely) excludes the point null (0) - whose credibility we’ve already seen has decreased by the observed data. This emphasizes the relationship between the support interval and the Bayes factor:</p>
<blockquote>
<p>“The interpretation of such intervals would be analogous to how a frequentist confidence interval contains all the parameter values that would not have been rejected if tested at level <span class="math inline">\(\alpha\)</span>. For instance, a BF = 1/3 support interval encloses all values of theta for which the updating factor is not stronger than 3 against.” <span class="citation">(Wagenmakers et al., 2018)</span></p>
</blockquote>
<p>Thus, the choice of BF (the level of support the interval should indicate) depends on what we want our interval to represent:</p>
<ul>
<li>A <span class="math inline">\(BF = 1\)</span> contains values whose credibility has merely not decreased by observing the data.<br>
</li>
<li>A <span class="math inline">\(BF &gt; 1\)</span> contains values who received more impressive support from the data.<br>
</li>
<li>A <span class="math inline">\(BF &lt; 1\)</span> contains values whose credibility has <em>not</em> been impressively decreased by observing the data. Testing against values outside this interval will produce a Bayes factor larger than <span class="math inline">\(1/BF\)</span> in support of the alternative.</li>
</ul>
</div>
</div>
<div id="bayesfactor_models" class="section level2">
<h2 class="hasAnchor">
<a href="#bayesfactor_models" class="anchor"></a>Comparing Models using Bayes Factors</h2>
<p>Bayes factors can also be used to compare statistical models, for which they answer the question:</p>
<blockquote>
<p><strong>Under which model are the observed data more probable?</strong></p>
</blockquote>
<p>In other words, which model is more likely to have produced the observed data? This is usually done by comparing the marginal likelihoods of two models. In such a case, the Bayes factor is a measure of the <em>relative</em> evidence of one of the compared models over the other.</p>
<p>Let’s use Bayes factors for model comparison to find a model that best describes the length of an iris’ sepal using the <code>iris</code> data set.</p>
<div id="for-bayesian-models-brms-and-rstanarm" class="section level3">
<h3 class="hasAnchor">
<a href="#for-bayesian-models-brms-and-rstanarm" class="anchor"></a>For Bayesian models (<code>brms</code> and <code>rstanarm</code>)</h3>
<p><strong>Note: In order to compute Bayes factors for Bayesian models, non-default arguments must be added upon fitting:</strong></p>
<ul>
<li>
<code>brmsfit</code> models <strong>must</strong> have been fitted with <code>save_pars = save_pars(all = TRUE)</code>
</li>
<li>
<code>stanreg</code> models <strong>must</strong> have been fitted with a defined <code>diagnostic_file</code>.</li>
</ul>
<p>Let’s first fit 5 Bayesian regressions with <code>brms</code> to predict <code>Sepal.Length</code>:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/paul-buerkner/brms">brms</a></span><span class="op">)</span>

<span class="va">m0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/brms/man/brm.html">brm</a></span><span class="op">(</span><span class="va">Sepal.Length</span> <span class="op">~</span> <span class="fl">1</span>, <span class="co"># intercept only model</span>
          data <span class="op">=</span> <span class="va">iris</span>, save_pars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/brms/man/save_pars.html">save_pars</a></span><span class="op">(</span>all <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span>
<span class="va">m1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/brms/man/brm.html">brm</a></span><span class="op">(</span><span class="va">Sepal.Length</span> <span class="op">~</span> <span class="va">Petal.Length</span>,
          data <span class="op">=</span> <span class="va">iris</span>, save_pars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/brms/man/save_pars.html">save_pars</a></span><span class="op">(</span>all <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span>
<span class="va">m2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/brms/man/brm.html">brm</a></span><span class="op">(</span><span class="va">Sepal.Length</span> <span class="op">~</span> <span class="va">Species</span>,
          data <span class="op">=</span> <span class="va">iris</span>, save_pars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/brms/man/save_pars.html">save_pars</a></span><span class="op">(</span>all <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span>
<span class="va">m3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/brms/man/brm.html">brm</a></span><span class="op">(</span><span class="va">Sepal.Length</span> <span class="op">~</span> <span class="va">Species</span> <span class="op">+</span> <span class="va">Petal.Length</span>,
          data <span class="op">=</span> <span class="va">iris</span>, save_pars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/brms/man/save_pars.html">save_pars</a></span><span class="op">(</span>all <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span>
<span class="va">m4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/brms/man/brm.html">brm</a></span><span class="op">(</span><span class="va">Sepal.Length</span> <span class="op">~</span> <span class="va">Species</span> <span class="op">*</span> <span class="va">Petal.Length</span>,
          data <span class="op">=</span> <span class="va">iris</span>, save_pars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/brms/man/save_pars.html">save_pars</a></span><span class="op">(</span>all <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>We can now compare these models with the <code><a href="../reference/bayesfactor_models.html">bayesfactor_models()</a></code> function, using the <code>denominator</code> argument to specify which model all models will be compared against (in this case, the intercept-only model):</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://easystats.github.io/bayestestR/">bayestestR</a></span><span class="op">)</span>
<span class="va">comparison</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bayesfactor_models.html">bayesfactor_models</a></span><span class="op">(</span><span class="va">m1</span>, <span class="va">m2</span>, <span class="va">m3</span>, <span class="va">m4</span>, denominator <span class="op">=</span> <span class="va">m0</span><span class="op">)</span>
<span class="va">comparison</span></code></pre></div>
<pre><code>&gt; # Bayes Factors for Model Comparison
&gt; 
&gt; Model                             BF
&gt; [1] Petal.Length           3.447e+44
&gt; [2] Species                5.629e+29
&gt; [3] Species + Petal.Length 7.121e+55
&gt; [4] Species * Petal.Length 9.150e+55
&gt; 
&gt; * Against Denominator: [5] (Intercept only)
&gt; *   Bayes Factor Type: marginal likelihoods (bridgesampling)</code></pre>
<p>We can see that the full model is the best model - with <span class="math inline">\(BF_{\text{m0}}=9\times 10^{55}\)</span> compared to the null (intercept only).</p>
<p>Due to the transitive property of Bayes factors, we can easily change the reference model to the main effects model:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">comparison</span>, reference <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></code></pre></div>
<pre><code>&gt; # Bayes Factors for Model Comparison
&gt; 
&gt; Model                             BF
&gt; [1] Petal.Length           4.841e-12
&gt; [2] Species                7.904e-27
&gt; [4] Species * Petal.Length     1.285
&gt; [5] (Intercept only)       1.404e-56
&gt; 
&gt; * Against Denominator: [3] Species + Petal.Length
&gt; *   Bayes Factor Type: marginal likelihoods (bridgesampling)</code></pre>
<p>As we can see, though the full model is the best, there is hardly any evidence that it is preferable to the main effects model.</p>
<p>We can also change the reference model to the <code>Species</code> model:</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">comparison</span>, reference <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></code></pre></div>
<pre><code>&gt; # Bayes Factors for Model Comparison
&gt; 
&gt; Model                             BF
&gt; [1] Petal.Length           6.125e+14
&gt; [3] Species + Petal.Length 1.265e+26
&gt; [4] Species * Petal.Length 1.626e+26
&gt; [5] (Intercept only)       1.777e-30
&gt; 
&gt; * Against Denominator: [2] Species
&gt; *   Bayes Factor Type: marginal likelihoods (bridgesampling)</code></pre>
<p>Notice that in the Bayesian framework the compared models <em>do not</em> need to be nested models, as happened here when we compared the <code>Petal.Length</code>-only model to the <code>Species</code>-only model (something that cannot be done in the frequentists framework, where compared models must be nested in one another).</p>
<p>We can also get a matrix of Bayes factors of all the pair-wise model comparisons:</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">comparison</span><span class="op">)</span></code></pre></div>
<pre><code>&gt; # Bayes Factors for Model Comparison 
&gt; 
&gt;                             Numerator
&gt; Denominator
&gt; 
&gt;                 |      [1] |      [2] |      [3] |      [4] |      [5]
&gt; ---------------------------------------------------------------------------------
&gt; [1] Petal.Length           |        1 | 1.63e-15 | 2.07e+11 | 2.65e+11 | 2.90e-45
&gt; [2] Species                | 6.12e+14 |        1 | 1.27e+26 | 1.63e+26 | 1.78e-30
&gt; [3] Species + Petal.Length | 4.84e-12 | 7.90e-27 |        1 |     1.28 | 1.40e-56
&gt; [4] Species * Petal.Length | 3.77e-12 | 6.15e-27 |     0.78 |        1 | 1.09e-56
&gt; [5] (Intercept only)       | 3.45e+44 | 5.63e+29 | 7.12e+55 | 9.15e+55 |        1</code></pre>
<p><strong>NOTE:</strong> In order to correctly and precisely estimate Bayes Factors, you always need the 4 P’s: <strong>P</strong>roper <strong>P</strong>riors,<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> and a <strong>P</strong>lentiful <strong>P</strong>osterior.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
</div>
<div id="for-frequentist-models-via-the-bic-approximation" class="section level3">
<h3 class="hasAnchor">
<a href="#for-frequentist-models-via-the-bic-approximation" class="anchor"></a>For Frequentist models via the BIC approximation</h3>
<p>It is also possible to compute Bayes factors for the comparison of frequentist models. This is done by comparing BIC measures, allowing a Bayesian comparison of non-nested frequentist models <span class="citation">(Wagenmakers, 2007)</span>. Let’s try it out on some <strong>linear mixed models</strong>:</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/lme4/lme4/">lme4</a></span><span class="op">)</span>

<span class="va">m0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">Sepal.Length</span> <span class="op">~</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">Species</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">iris</span><span class="op">)</span>
<span class="va">m1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">Sepal.Length</span> <span class="op">~</span> <span class="va">Petal.Length</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">Species</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">iris</span><span class="op">)</span>
<span class="va">m2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">Sepal.Length</span> <span class="op">~</span> <span class="va">Petal.Length</span> <span class="op">+</span> <span class="op">(</span><span class="va">Petal.Length</span> <span class="op">|</span> <span class="va">Species</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">iris</span><span class="op">)</span>
<span class="va">m3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">Sepal.Length</span> <span class="op">~</span> <span class="va">Petal.Length</span> <span class="op">+</span> <span class="va">Petal.Width</span> <span class="op">+</span> <span class="op">(</span><span class="va">Petal.Length</span> <span class="op">|</span> <span class="va">Species</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">iris</span><span class="op">)</span>
<span class="va">m4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">Sepal.Length</span> <span class="op">~</span> <span class="va">Petal.Length</span> <span class="op">*</span> <span class="va">Petal.Width</span> <span class="op">+</span> <span class="op">(</span><span class="va">Petal.Length</span> <span class="op">|</span> <span class="va">Species</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">iris</span><span class="op">)</span>

<span class="fu"><a href="../reference/bayesfactor_models.html">bayesfactor_models</a></span><span class="op">(</span><span class="va">m1</span>, <span class="va">m2</span>, <span class="va">m3</span>, <span class="va">m4</span>, denominator <span class="op">=</span> <span class="va">m0</span><span class="op">)</span></code></pre></div>
<pre><code>&gt; # Bayes Factors for Model Comparison
&gt; 
&gt; Model                                                            BF
&gt; [1] Petal.Length + (1 | Species)                          8.240e+24
&gt; [2] Petal.Length + (Petal.Length | Species)               4.768e+23
&gt; [3] Petal.Length + Petal.Width + (Petal.Length | Species) 1.525e+22
&gt; [4] Petal.Length * Petal.Width + (Petal.Length | Species) 5.930e+20
&gt; 
&gt; * Against Denominator: [5] 1 + (1 | Species)
&gt; *   Bayes Factor Type: BIC approximation</code></pre>
</div>
<div id="bayesfactor_restricted" class="section level3">
<h3 class="hasAnchor">
<a href="#bayesfactor_restricted" class="anchor"></a>Order restricted models</h3>
<p>As stated above when discussing one-sided hypothesis tests, we can create new models by imposing order restrictions on a given model. For example, consider the following model, in which we predict the length of an iris’ sepal from the length of its petal, as well as from its species, with a prior of <span class="math inline">\(b_{petal} \sim N(0,2)\)</span> <span class="math inline">\(b_{versicolors}\ \&amp;\  b_{virginica} \sim N(0,1.2)\)</span>:</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">iris_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span><span class="op">(</span><span class="va">Sepal.Length</span> <span class="op">~</span> <span class="va">Species</span> <span class="op">+</span> <span class="va">Petal.Length</span>,
                       data <span class="op">=</span> <span class="va">iris</span>,
                       prior <span class="op">=</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/priors.html">normal</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">1.2</span>, <span class="fl">1.2</span><span class="op">)</span>, autoscale <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>These priors are <strong>unrestricted</strong> - that is, all values between <span class="math inline">\(-\infty\)</span> and <span class="math inline">\(\infty\)</span> of all parameters in the model have some non-zero credibility (no matter how small; this is true for both the prior and posterior distribution). Subsequently, <em>a priori</em> the ordering of the parameters relating to the iris species can have any ordering, such that (a priori) setosa can have larger sepals than virginica, but it is also possible for virginica to have larger sepals than setosa!</p>
<p>Does it make sense to let our priors cover all of these possibilities? That depends on our <em>prior</em> knowledge or hypotheses. For example, even a novice botanist will assume that it is unlikely that petal length will be <em>negatively</em> associated with sepal length - an iris with longer petals is likely larger, and thus will also have a longer sepal. And an expert botanist will perhaps assume that setosas have smaller sepals than both versicolors and virginica. These priors can be formulated as <strong>restricted</strong> priors <span class="citation">(Morey, 2015; Morey &amp; Rouder, 2011)</span>:</p>
<ol style="list-style-type: decimal">
<li>The novice botanist: <span class="math inline">\(b_{petal} &gt; 0\)</span>
</li>
<li>The expert botanist: <span class="math inline">\(b_{versicolors} &gt; 0\ \&amp;\ b_{virginica} &gt; 0\)</span>
</li>
</ol>
<p>By testing these restrictions on prior and posterior samples, we can see how the probabilities of the restricted distributions change after observing the data. This can be achieved with <code><a href="../reference/bayesfactor_restricted.html">bayesfactor_restricted()</a></code>, that compute a Bayes factor for these restricted model vs the unrestricted model. Let’s first specify these restrictions as logical conditions:</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">botanist_hypotheses</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>
  <span class="st">"Petal.Length &gt; 0"</span>,
  <span class="st">"(Speciesversicolor &gt; 0) &amp; (Speciesvirginica &gt; 0)"</span>
<span class="op">)</span></code></pre></div>
<p>Let’s test these hypotheses:</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">botanist_BFs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bayesfactor_restricted.html">bayesfactor_restricted</a></span><span class="op">(</span><span class="va">iris_model</span>, hypothesis <span class="op">=</span> <span class="va">botanist_hypotheses</span><span class="op">)</span>
<span class="va">botanist_BFs</span></code></pre></div>
<pre><code>&gt; # Bayes Factor (Order-Restriction)
&gt; 
&gt; Hypothesis                                       P(Prior) P(Posterior)    BF
&gt; Petal.Length &gt; 0                                    0.495            1 2.018
&gt; (Speciesversicolor &gt; 0) &amp; (Speciesvirginica &gt; 0)    0.244            0 0.000
&gt; 
&gt; * Bayes factors for the restricted model vs. the un-restricted model.</code></pre>
<p>We can see that the novice botanist’s hypothesis gets a Bayes factor of ~2, indicating the data provides twice as much evidence for a model in which petal length is restricted to be positively associated with sepal length than for a model with not such restriction.</p>
<p>What about our expert botanist? He seems to have failed miserably, with a BF favoring the <em>unrestricted</em> model many many times over (<span class="math inline">\(BF\gg1,000\)</span>). How is this possible? It seems that when <em>controlling for petal length</em>, versicolor and virginica actually have shorter sepals!</p>
<p><img src="bayes_factors_files/figure-html/plot_iris-1.png" width="1093.75"></p>
<p>Note that these Bayes factors compare the restricted model to the unrestricted model. If we wanted to compare the restricted model to the null model, we could use the transitive property of Bayes factors like so:</p>
<p><span class="math display">\[
BF_{\text{restricted vs. NULL}} = \frac
{BF_{\text{restricted vs. un-restricted}}}
{BF_{\text{un-restricted vs NULL}}}
\]</span></p>
<p><strong>Because these restrictions are on the prior distribution, they are only appropriate for testing pre-planned (<em>a priori</em>) hypotheses, and should not be used for any post hoc comparisons <span class="citation">(Morey, 2015)</span>.</strong></p>
<p><strong>NOTE</strong>: See the <em>Specifying Correct Priors for Factors with More Than 2 Levels</em> appendix below.</p>
</div>
</div>
<div id="bayesian-model-averaging" class="section level2">
<h2 class="hasAnchor">
<a href="#bayesian-model-averaging" class="anchor"></a>Bayesian Model Averaging</h2>
<p>In the previous section we discussed the direct comparison of two models to determine if an effect is supported by the data. However, in many cases there are too many models to consider or perhaps it is not straightforward which models we should compare to determine if an effect is supported by the data. For such cases we can use Bayesian model averaging (BMA) to determine the support provided by the data for a parameter or term across many models.</p>
<div id="bayesfactor_inclusion" class="section level3">
<h3 class="hasAnchor">
<a href="#bayesfactor_inclusion" class="anchor"></a>Inclusion Bayes factors</h3>
<p>Inclusion Bayes factors answer the question:</p>
<blockquote>
<p><strong>Are the observed data more probable under models with a particular predictor, than they are under models without that particular predictor?</strong></p>
</blockquote>
<p>In other words, on average - are models with predictor <span class="math inline">\(X\)</span> more likely to have produced the observed data than models without predictor <span class="math inline">\(X\)</span>?<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></p>
<p>Since each model has a prior probability, it is possible to sum the prior probability of all models that include a predictor of interest (the <em>prior inclusion probability</em>), and of all models that do not include that predictor (the <em>prior exclusion probability</em>). After the data are observed, and each model is assigned a posterior probability, we can similarly consider the sums of the posterior models’ probabilities to obtain the <em>posterior inclusion probability</em> and the <em>posterior exclusion probability</em>. Once again, the change from prior inclusion odds to the posterior inclusion odds is the Inclusion Bayes factor <span class="citation">(“<span class="math inline">\(BF_{Inclusion}\)</span>”; Clyde, Ghosh, &amp; Littman, 2011)</span>.</p>
<p>Lets use the <code>brms</code> example from above:</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/bayesfactor_inclusion.html">bayesfactor_inclusion</a></span><span class="op">(</span><span class="va">comparison</span><span class="op">)</span></code></pre></div>
<pre><code>&gt; # Inclusion Bayes Factors (Model Averaged)
&gt; 
&gt;                      Pr(prior) Pr(posterior) Inclusion BF
&gt; Petal.Length             0.600         1.000    1.927e+26
&gt; Species                  0.600         1.000    3.147e+11
&gt; Petal.Length:Species     0.200         0.562        5.139
&gt; 
&gt; * Compared among: all models
&gt; *    Priors odds: uniform-equal</code></pre>
<p>If we examine the interaction term’s inclusion Bayes factor, we can see that across all 5 models, a model with the interaction term (<code>Species:Petal.Length</code>) is <em>on average</em> 5 times more likely than a model without the interaction term. <strong>Note</strong> that <code>Species</code>, a factor represented in the model with several parameters, gets a single Bayes factor - inclusion Bayes factors are given per predictor!</p>
<p>We can also compare only matched models - such that averaging is done only across models that (1) do not include any interactions with the predictor of interest; (2) for interaction predictors, averaging is done only across models that contain the main effect from which the interaction predictor is comprised (see explanation for why you might want to do this <a href="https://www.cogsci.nl/blog/interpreting-bayesian-repeated-measures-in-jasp">here</a>).</p>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/bayesfactor_inclusion.html">bayesfactor_inclusion</a></span><span class="op">(</span><span class="va">comparison</span>, match_models <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
<pre><code>&gt; # Inclusion Bayes Factors (Model Averaged)
&gt; 
&gt;                      Pr(prior) Pr(posterior) Inclusion BF
&gt; Petal.Length             0.400         0.438    1.265e+26
&gt; Species                  0.400         0.438    2.066e+11
&gt; Petal.Length:Species     0.200         0.562        1.285
&gt; 
&gt; * Compared among: matched models only
&gt; *    Priors odds: uniform-equal</code></pre>
<div id="comparison-with-jasp" class="section level4">
<h4 class="hasAnchor">
<a href="#comparison-with-jasp" class="anchor"></a>Comparison with JASP</h4>
<p><code><a href="../reference/bayesfactor_inclusion.html">bayesfactor_inclusion()</a></code> is meant to provide Bayes Factors per predictor, similar to JASP’s <em>Effects</em> option. Let’s compare the two:</p>
<ol style="list-style-type: decimal">
<li>Across all models:</li>
</ol>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://richarddmorey.github.io/BayesFactor/">BayesFactor</a></span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">ToothGrowth</span><span class="op">)</span>
<span class="va">ToothGrowth</span><span class="op">$</span><span class="va">dose</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">ToothGrowth</span><span class="op">$</span><span class="va">dose</span><span class="op">)</span>

<span class="va">BF_ToothGrowth</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/BayesFactor/man/anovaBF.html">anovaBF</a></span><span class="op">(</span><span class="va">len</span> <span class="op">~</span> <span class="va">dose</span><span class="op">*</span><span class="va">supp</span>, <span class="va">ToothGrowth</span>, progress <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>

<span class="fu"><a href="../reference/bayesfactor_inclusion.html">bayesfactor_inclusion</a></span><span class="op">(</span><span class="va">BF_ToothGrowth</span><span class="op">)</span></code></pre></div>
<pre><code>&gt; # Inclusion Bayes Factors (Model Averaged)
&gt; 
&gt;           Pr(prior) Pr(posterior) Inclusion BF
&gt; supp          0.600         0.995      140.992
&gt; dose          0.600         1.000    3.211e+14
&gt; dose:supp     0.200         0.717       10.121
&gt; 
&gt; * Compared among: all models
&gt; *    Priors odds: uniform-equal</code></pre>
<p><img src="https://github.com/easystats/easystats/raw/master/man/figures/bayestestR/JASP1.PNG"><!-- --></p>
<ol start="2" style="list-style-type: decimal">
<li>Across matched models:</li>
</ol>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/bayesfactor_inclusion.html">bayesfactor_inclusion</a></span><span class="op">(</span><span class="va">BF_ToothGrowth</span>, match_models <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
<pre><code>&gt; # Inclusion Bayes Factors (Model Averaged)
&gt; 
&gt;           Pr(prior) Pr(posterior) Inclusion BF
&gt; supp          0.400         0.279       59.191
&gt; dose          0.400         0.283    1.364e+14
&gt; dose:supp     0.200         0.717        2.573
&gt; 
&gt; * Compared among: matched models only
&gt; *    Priors odds: uniform-equal</code></pre>
<p><img src="https://github.com/easystats/easystats/raw/master/man/figures/bayestestR/JASP2.PNG"><!-- --></p>
<ol start="3" style="list-style-type: decimal">
<li>With Nuisance Effects:</li>
</ol>
<p>We’ll add <code>dose</code> to the null model in JASP, and do the same in <code>R</code>:</p>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">BF_ToothGrowth_against_dose</span> <span class="op">&lt;-</span> <span class="va">BF_ToothGrowth</span><span class="op">[</span><span class="fl">3</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span><span class="op">/</span><span class="va">BF_ToothGrowth</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="co"># OR: </span>
<span class="co"># update(bayesfactor_models(BF_ToothGrowth),</span>
<span class="co">#        subset = c(4, 5),</span>
<span class="co">#        reference = 3)</span>
<span class="va">BF_ToothGrowth_against_dose</span></code></pre></div>
<pre><code>&gt; Bayes factor analysis
&gt; --------------
&gt; [1] supp + dose             : 59  ±4.5%
&gt; [2] supp + dose + supp:dose : 152 ±1.5%
&gt; 
&gt; Against denominator:
&gt;   len ~ dose 
&gt; ---
&gt; Bayes factor type: BFlinearModel, JZS</code></pre>
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/bayesfactor_inclusion.html">bayesfactor_inclusion</a></span><span class="op">(</span><span class="va">BF_ToothGrowth_against_dose</span><span class="op">)</span></code></pre></div>
<pre><code>&gt; # Inclusion Bayes Factors (Model Averaged)
&gt; 
&gt;           Pr(prior) Pr(posterior) Inclusion BF
&gt; dose          1.000         1.000           NA
&gt; supp          0.667         0.995      105.744
&gt; dose:supp     0.333         0.717        5.060
&gt; 
&gt; * Compared among: all models
&gt; *    Priors odds: uniform-equal</code></pre>
<p><img src="https://github.com/easystats/easystats/raw/master/man/figures/bayestestR/JASP3.PNG"><!-- --></p>
</div>
</div>
<div id="weighted_posteriors" class="section level3">
<h3 class="hasAnchor">
<a href="#weighted_posteriors" class="anchor"></a>Averaging posteriors</h3>
<p>Similar to how we can average evidence for a predictor across models, we can also average the posterior estimate across models. One situation in which this is useful in <strong>situations where Bayes factors seem to support a null effect, yet the <em>HDI</em> of the alternative excludes the null value</strong> (also see <code><a href="../reference/si.html">si()</a></code> described above). For example, looking at Motor <em>Trend Car Road Tests</em> (<code><a href="https://rdrr.io/r/utils/data.html">data(mtcars)</a></code>), we would naturally predict miles/gallon (<code>mpg</code>) from transition type (<code>am</code>) and weight (<code>wt</code>), but what about number of carburetors (<code>carb</code>)? Is this a good predictor?</p>
<p>We can determine this by comparing the following models:</p>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span><span class="op">(</span><span class="va">mpg</span> <span class="op">~</span> <span class="va">wt</span> <span class="op">+</span> <span class="va">am</span>,            
                data <span class="op">=</span> <span class="va">mtcars</span>,
                prior <span class="op">=</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/priors.html">normal</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">10</span>,<span class="fl">10</span><span class="op">)</span>, autoscale <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>,
                diagnostic_file <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/tempfile.html">tempdir</a></span><span class="op">(</span><span class="op">)</span>, <span class="st">"df1.csv"</span><span class="op">)</span><span class="op">)</span>

<span class="va">mod_carb</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span><span class="op">(</span><span class="va">mpg</span> <span class="op">~</span> <span class="va">wt</span> <span class="op">+</span> <span class="va">am</span> <span class="op">+</span> <span class="va">carb</span>,            
                     data <span class="op">=</span> <span class="va">mtcars</span>,
                     prior <span class="op">=</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/priors.html">normal</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">10</span>,<span class="fl">10</span>,<span class="fl">20</span><span class="op">)</span>, autoscale <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>,
                     diagnostic_file <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/tempfile.html">tempdir</a></span><span class="op">(</span><span class="op">)</span>, <span class="st">"df0.csv"</span><span class="op">)</span><span class="op">)</span>

<span class="fu"><a href="../reference/bayesfactor_models.html">bayesfactor_models</a></span><span class="op">(</span><span class="va">mod_carb</span>, denominator <span class="op">=</span> <span class="va">mod</span><span class="op">)</span></code></pre></div>
<pre><code>&gt; # Bayes Factors for Model Comparison
&gt; 
&gt; Model                 BF
&gt; [1] wt + am + carb 0.811
&gt; 
&gt; * Against Denominator: [2] wt + am
&gt; *   Bayes Factor Type: marginal likelihoods (bridgesampling)</code></pre>
<p>It seems that the model without <code>carb</code> as a predictor is <span class="math inline">\(1/BF=1.2\)</span> times more likely than the model <em>with</em> <code>carb</code> as a predictor. We might then assume that in the latter model, the HDI will include the point-null value of 0 effect, to also indicate the credibility of the null in the posterior. However, this is not the case:</p>
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/hdi.html">hdi</a></span><span class="op">(</span><span class="va">mod_carb</span>, ci <span class="op">=</span> <span class="fl">.95</span><span class="op">)</span></code></pre></div>
<pre><code>&gt; # Highest Density Interval
&gt; 
&gt; Parameter   |        95% HDI
&gt; ----------------------------
&gt; (Intercept) | [28.10, 40.09]
&gt; wt          | [-5.48, -1.72]
&gt; am          | [-0.81,  5.86]
&gt; carb        | [-2.04, -0.38]</code></pre>
<p>How can this be? By estimating the HDI of the effect for <code>carb</code> in the full model, we are acting under the assumption that that model is correct. However, as we’ve just seen, both models are practically tied, and in fact it was the no-<code>carb</code> model, in which the effect for <code>carb</code> is fixed at 0, that was slightly more supported by the data. If this is the case <strong>why limit our estimation of the effect just to one model?</strong> <span class="citation">(Bergh, Haaf, Ly, Rouder, &amp; Wagenmakers, 2019)</span>.</p>
<p>Using Bayesian model averaging, we can combine the posteriors samples from several models, weighted by the models’ marginal likelihood (done via the <code><a href="../reference/bayesfactor_models.html">bayesfactor_models()</a></code> function). If some parameter is part of some of the models but is missing from others, it is assumed to be fixed a 0 (which can also be seen as a method of applying shrinkage to our estimates). This results in a posterior distribution across several models, which we can now treat like any posterior distribution, and estimate the HDI. We can do this with the <code><a href="../reference/weighted_posteriors.html">weighted_posteriors()</a></code> function:</p>
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">BMA_draws</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/weighted_posteriors.html">weighted_posteriors</a></span><span class="op">(</span><span class="va">mod</span>, <span class="va">mod_carb</span><span class="op">)</span>

<span class="va">BMA_hdi</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hdi.html">hdi</a></span><span class="op">(</span><span class="va">BMA_draws</span>, ci <span class="op">=</span> <span class="fl">.95</span><span class="op">)</span>
<span class="va">BMA_hdi</span></code></pre></div>
<pre><code>&gt; # Highest Density Interval
&gt; 
&gt; Parameter   |        95% HDI
&gt; ----------------------------
&gt; (Intercept) | [29.03, 42.43]
&gt; wt          | [-6.66, -2.14]
&gt; am          | [-2.80,  5.04]
&gt; carb        | [-1.69,  0.00]</code></pre>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">BMA_hdi</span><span class="op">)</span></code></pre></div>
<p><img src="bayes_factors_files/figure-html/unnamed-chunk-25-1.png" width="1093.75"></p>
<p>We can see that across both models under consideration, the posterior of the <code>carb</code> effect is almost equally weighted between the alternative model and the null model - as represented by about half of the posterior mass concentrated at 0 - which makes sense as both models were almost equally supported by the data. We can also see that across both models, that now <strong>the HDI does contain 0</strong>. Thus we have resolved the conflict between the Bayes factor and the HDI <span class="citation">(Rouder, Haaf, &amp; Vandekerckhove, 2018)</span>!</p>
<p><strong>Note</strong> that parameters might play different roles across different models; For example, the parameter <code>A</code> plays a different role in the model <code>Y ~ A + B</code> (where it is a main effect) than it does in the model <code>Y ~ A + B + A:B</code> (where it is a simple effect). In many cases centering of predictors (mean subtracting for continuous variables, and effects coding via <code>contr.sum</code> or orthonormal coding via <a href="https://easystats.github.io/bayestestR/reference/contr.bayes.html"><code>contr.bayes</code></a> for factors) can in some cases reduce this issue.</p>
</div>
</div>
<div id="appendices" class="section level2">
<h2 class="hasAnchor">
<a href="#appendices" class="anchor"></a>Appendices</h2>
<div id="testing-contrasts-with-emmeans-modelbased" class="section level3">
<h3 class="hasAnchor">
<a href="#testing-contrasts-with-emmeans-modelbased" class="anchor"></a>Testing contrasts (with <code>emmeans</code> / <code>modelbased</code>)</h3>
<p>Besides testing parameter <code><a href="../reference/bayesfactor_parameters.html">bayesfactor_parameters()</a></code> can be used to test any estimate based on the prior and posterior distribution of the estimate. One way to achieve this is with a mix of <code><a href="../reference/bayesfactor_parameters.html">bayesfactor_parameters()</a></code> + <a href="https://cran.r-project.org/package=emmeans"><strong><code>emmeans</code></strong></a> to <a href="https://easystats.github.io/blog/posts/bayestestr_emmeans/">test Bayesian contrasts</a>.</p>
<p>For example, in the <code>sleep</code> example from above, we can estimate the group means and the difference between them:</p>
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rvlenth/emmeans">emmeans</a></span><span class="op">)</span>

<span class="va">groups</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/emmeans/man/emmeans.html">emmeans</a></span><span class="op">(</span><span class="va">model</span>, <span class="op">~</span> <span class="va">group</span><span class="op">)</span>
<span class="va">group_diff</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">groups</span><span class="op">)</span>

<span class="op">(</span><span class="va">groups_all</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">groups</span>, <span class="va">group_diff</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>&gt;  group contrast emmean lower.HPD upper.HPD
&gt;  1     .          0.79      -0.5       2.0
&gt;  2     .          2.28       1.0       3.5
&gt;  .     1 - 2     -1.47      -3.2       0.2
&gt; 
&gt; Point estimate displayed: median 
&gt; HPD interval probability: 0.95</code></pre>
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># pass the original model via prior</span>
<span class="fu"><a href="../reference/bayesfactor_parameters.html">bayesfactor_parameters</a></span><span class="op">(</span><span class="va">groups_all</span>, prior <span class="op">=</span> <span class="va">model</span><span class="op">)</span></code></pre></div>
<pre><code>&gt; # Bayes Factor (Savage-Dickey density ratio)
&gt; 
&gt; Parameter |     BF
&gt; ------------------
&gt; 1, .      |  0.287
&gt; 2, .      | 19.961
&gt; ., 1 - 2  |  1.256
&gt; 
&gt; * Evidence Against The Null: [0]</code></pre>
<p>That is strong evidence for the mean of group 1 being 0, and for group 2 for not being 0, but hardly any evidence for the difference between them being not 0. Conflict? Uncertainty? That is the Bayesian way!</p>
<p>We can also use the <code>easystats</code>’ <a href="https://cran.r-project.org/package=modelbased"><strong><code>modelbased</code></strong></a> package to compute Bayes factors for contrasts:</p>
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://easystats.github.io/modelbased/">modelbased</a></span><span class="op">)</span>

<span class="fu"><a href="https://easystats.github.io/modelbased/reference/estimate_contrasts.html">estimate_contrasts</a></span><span class="op">(</span><span class="va">model</span>, test <span class="op">=</span> <span class="st">"bf"</span><span class="op">)</span></code></pre></div>
<p><strong>NOTE</strong>: See the <em>Specifying Correct Priors for Factors with More Than 2 Levels</em> section below.</p>
</div>
<div id="contr_bayes" class="section level3">
<h3 class="hasAnchor">
<a href="#contr_bayes" class="anchor"></a>Specifying correct priors for factors</h3>
<p>This section introduces the biased priors obtained when using the common <em>effects</em> factor coding (<code>contr.sum</code>) or dummy factor coding (<code>contr.treatment</code>), and the solution of using orthonormal factor coding (<code>contr.bayes</code>) <span class="citation">(as outlined in Rouder, Morey, Speckman, &amp; Province, 2012, sec. 7.2)</span>. Specifically, <strong><em>special care should be taken when working with factors which have 3 or more levels</em></strong>.</p>
<div id="contrasts-and-marginal-means" class="section level4">
<h4 class="hasAnchor">
<a href="#contrasts-and-marginal-means" class="anchor"></a>Contrasts (and marginal means)</h4>
<p>The <em>effects</em> factor coding commonly used in factorial analysis carries a hidden bias when it is applies to Bayesian priors. For example, if we want to test all pairwise differences between 3 levels of the same factor, we would expect all <em>a priori</em> differences to have the same distribution, but…</p>
<p>For our example, we will be test all <strong><em>prior</em></strong> pairwise differences between the 3 species in the <code>iris</code> data-set.</p>
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">df</span> <span class="op">&lt;-</span> <span class="va">iris</span>
<span class="fu"><a href="https://rdrr.io/r/stats/contrasts.html">contrasts</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="va">contr.sum</span>

<span class="va">fit_sum</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span><span class="op">(</span><span class="va">Sepal.Length</span> <span class="op">~</span> <span class="va">Species</span>, data <span class="op">=</span> <span class="va">df</span>,
                    prior <span class="op">=</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/priors.html">normal</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>, autoscale <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>,
                    prior_PD <span class="op">=</span> <span class="cn">TRUE</span>, <span class="co"># sample priors</span>
                    family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">gaussian</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span>

<span class="va">pairs_sum</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/emmeans/man/emmeans.html">emmeans</a></span><span class="op">(</span><span class="va">fit_sum</span>, <span class="op">~</span> <span class="va">Species</span><span class="op">)</span><span class="op">)</span>
<span class="va">pairs_sum</span></code></pre></div>
<pre><code>&gt;  contrast               estimate lower.HPD upper.HPD
&gt;  setosa - versicolor      -0.017      -2.8       2.7
&gt;  setosa - virginica       -0.027      -4.0       4.6
&gt;  versicolor - virginica    0.001      -4.2       4.5
&gt; 
&gt; Point estimate displayed: median 
&gt; HPD interval probability: 0.95</code></pre>
<p><img src="bayes_factors_files/figure-html/unnamed-chunk-31-1.png" width="1093.75"></p>
<p>We can see that the though the prior estimate for all 3 pairwise contrasts is ~0, the scale / HDI is much more narrow for the prior of the <code>setosa - versicolor</code> contrast!</p>
<p><strong><em>What happened???</em></strong><br>
This is caused by an inherent bias in the priors introduced by the <em>effects</em> coding (it’s even worse with the default treatment coding, because the prior for the intercept is usually drastically different from the effect’s parameters). <strong>And since it affects the priors, this bias will also bias the Bayes factors over / understating evidence for some contrasts over others!</strong></p>
<p>The solution is to use <em>orthonormal</em> factor coding, a-la <code>contr.bayes</code>, which can either specify this factor coding per-factor:</p>
<div class="sourceCode" id="cb60"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/contrasts.html">contrasts</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="va">contr.bayes</span></code></pre></div>
<p>Or you can set it globally:</p>
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/options.html">options</a></span><span class="op">(</span>contrasts <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'contr.bayes'</span>, <span class="st">'contr.poly'</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>Let’s again estimate the <strong><em>prior</em></strong> differences:</p>
<div class="sourceCode" id="cb62"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit_bayes</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span><span class="op">(</span><span class="va">Sepal.Length</span> <span class="op">~</span> <span class="va">Species</span>, data <span class="op">=</span> <span class="va">df</span>,
                      prior <span class="op">=</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/priors.html">normal</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>, autoscale <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>,
                      prior_PD <span class="op">=</span> <span class="cn">TRUE</span>, <span class="co"># sample priors</span>
                      family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">gaussian</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span>

<span class="va">pairs_bayes</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/emmeans/man/emmeans.html">emmeans</a></span><span class="op">(</span><span class="va">fit_bayes</span>, <span class="op">~</span> <span class="va">Species</span><span class="op">)</span><span class="op">)</span>
<span class="va">pairs_bayes</span></code></pre></div>
<pre><code>&gt;  contrast               estimate lower.HPD upper.HPD
&gt;  setosa - versicolor       0.000     -2.98      2.67
&gt;  setosa - virginica        0.032     -2.73      2.81
&gt;  versicolor - virginica    0.003     -2.91      2.67
&gt; 
&gt; Point estimate displayed: median 
&gt; HPD interval probability: 0.95</code></pre>
<p><img src="bayes_factors_files/figure-html/unnamed-chunk-35-1.png" width="1093.75"></p>
<p>We can see that using this coding scheme, we have equal priors on all pairwise contrasts.</p>
</div>
<div id="order-restrictions" class="section level4">
<h4 class="hasAnchor">
<a href="#order-restrictions" class="anchor"></a>Order restrictions</h4>
<p>This bias also affect order restrictions involving 3 or more levels. For example, if we want to test an order restriction among A, B, and C, the <em>a priori</em> probability of obtaining the order A &gt; C &gt; B is 1/6 (reach back to <em>intro to stats</em> year 1), but…</p>
<p>For our example, we will be interested in the following order restrictions in the <code>iris</code> data-set (each line is a separate restriction):</p>
<div class="sourceCode" id="cb64"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">hyp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>
  <span class="co"># comparing 2 levels</span>
  <span class="st">"setosa &lt; versicolor"</span>,
  <span class="st">"setosa &lt; virginica"</span>,
  <span class="st">"versicolor &lt; virginica"</span>,
  
  <span class="co"># comparing 3 (or more) levels</span>
  <span class="st">"setosa    &lt; virginica  &amp; virginica  &lt; versicolor"</span>,
  <span class="st">"virginica &lt; setosa     &amp; setosa     &lt; versicolor"</span>,
  <span class="st">"setosa    &lt; versicolor &amp; versicolor &lt; virginica"</span>
<span class="op">)</span></code></pre></div>
<p>With the default factor coding, this looks like this:</p>
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/contrasts.html">contrasts</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="va">contr.sum</span>

<span class="va">fit_sum</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span><span class="op">(</span><span class="va">Sepal.Length</span> <span class="op">~</span> <span class="va">Species</span>, data <span class="op">=</span> <span class="va">df</span>,
                    prior <span class="op">=</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/priors.html">normal</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>, autoscale <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>,
                    family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">gaussian</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span>

<span class="va">em_sum</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/emmeans/man/emmeans.html">emmeans</a></span><span class="op">(</span><span class="va">fit_sum</span>, <span class="op">~</span> <span class="va">Species</span><span class="op">)</span> <span class="co"># the posterior marginal means</span>
  
<span class="fu"><a href="../reference/bayesfactor_restricted.html">bayesfactor_restricted</a></span><span class="op">(</span><span class="va">em_sum</span>, <span class="va">fit_sum</span>, hypothesis <span class="op">=</span> <span class="va">hyp</span><span class="op">)</span></code></pre></div>
<pre><code>&gt; # Bayes Factor (Order-Restriction)
&gt; 
&gt; Hypothesis                                       P(Prior) P(Posterior)    BF
&gt; setosa &lt; versicolor                                 0.508            1 1.969
&gt; setosa &lt; virginica                                  0.495            1 2.020
&gt; versicolor &lt; virginica                              0.491            1 2.035
&gt; setosa    &lt; virginica  &amp; virginica  &lt; versicolor    0.107            0 0.000
&gt; virginica &lt; setosa     &amp; setosa     &lt; versicolor    0.204            0 0.000
&gt; setosa    &lt; versicolor &amp; versicolor &lt; virginica     0.197            1 5.089
&gt; 
&gt; * Bayes factors for the restricted model vs. the un-restricted model.</code></pre>
<p><strong><em>What happened???</em></strong></p>
<ol style="list-style-type: decimal">
<li>The comparison of 2 levels all have a prior of ~0.5, as expected.<br>
</li>
<li>The comparison of 3 levels has different priors, depending on the order restriction - i.e. <strong>some orders are <em>a priori</em> more likely than others!!!</strong>
</li>
</ol>
<p>Again, this is solved by using the <em>orthonormal</em> factor coding (from above).</p>
<div class="sourceCode" id="cb67"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/contrasts.html">contrasts</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="va">contr.bayes</span>

<span class="va">fit_bayes</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span><span class="op">(</span><span class="va">Sepal.Length</span> <span class="op">~</span> <span class="va">Species</span>, data <span class="op">=</span> <span class="va">df</span>,
                      prior <span class="op">=</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/priors.html">normal</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>, autoscale <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>,
                      family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">gaussian</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span>

<span class="va">em_bayes</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/emmeans/man/emmeans.html">emmeans</a></span><span class="op">(</span><span class="va">fit_sum</span>, <span class="op">~</span> <span class="va">Species</span><span class="op">)</span> <span class="co"># the posterior marginal means</span>

<span class="fu"><a href="../reference/bayesfactor_restricted.html">bayesfactor_restricted</a></span><span class="op">(</span><span class="va">em_bayes</span>, <span class="va">fit_sum</span>, hypothesis <span class="op">=</span> <span class="va">hyp</span><span class="op">)</span></code></pre></div>
<pre><code>&gt; # Bayes Factor (Order-Restriction)
&gt; 
&gt; Hypothesis                                       P(Prior) P(Posterior)    BF
&gt; setosa &lt; versicolor                                 0.486            1 2.055
&gt; setosa &lt; virginica                                  0.493            1 2.028
&gt; versicolor &lt; virginica                              0.509            1 1.965
&gt; setosa    &lt; virginica  &amp; virginica  &lt; versicolor    0.167            0 0.000
&gt; virginica &lt; setosa     &amp; setosa     &lt; versicolor    0.156            0 0.000
&gt; setosa    &lt; versicolor &amp; versicolor &lt; virginica     0.164            1 6.107
&gt; 
&gt; * Bayes factors for the restricted model vs. the un-restricted model.</code></pre>
</div>
<div id="conclusion" class="section level4">
<h4 class="hasAnchor">
<a href="#conclusion" class="anchor"></a>Conclusion</h4>
<p>When comparing the results from the two factor coding schemes, we find:<br>
1. In both cases, the estimated (posterior) means are quite similar (if not identical).<br>
2. The priors and Bayes factors differ between the two schemes.<br>
3. Only with <code>contr.bayes</code>, the prior distribution of the difference or the order of 3 (or more) means is balanced.</p>
</div>
</div>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>
<div id="refs" class="references">
<div id="ref-van2019cautionary">
<p>Bergh, D. van den, Haaf, J. M., Ly, A., Rouder, J. N., &amp; Wagenmakers, E.-J. (2019). <em>A cautionary note on estimating effect size</em>.</p>
</div>
<div id="ref-clyde2011bayesian">
<p>Clyde, M. A., Ghosh, J., &amp; Littman, M. L. (2011). Bayesian adaptive sampling for variable selection and model averaging. <em>Journal of Computational and Graphical Statistics</em>, <em>20</em>(1), 80–101.</p>
</div>
<div id="ref-kruschke2010believe">
<p>Kruschke, J. K. (2010). What to believe: Bayesian methods for data analysis. <em>Trends in Cognitive Sciences</em>, <em>14</em>(7), 293–300.</p>
</div>
<div id="ref-morey_2015_blog">
<p>Morey, R. D. (2015). <em>Multiple comparisons with bayesfactor, part 2 – order restrictions</em>. Retrieved from <a href="http://bayesfactor.blogspot.com/2015/01/multiple-comparisons-with-bayesfactor-2.html">http://bayesfactor.blogspot.com/2015/01/multiple-comparisons-with-bayesfactor-2.html</a></p>
</div>
<div id="ref-morey2011bayesinterval">
<p>Morey, R. D., &amp; Rouder, J. N. (2011). Bayes factor approaches for testing interval null hypotheses. <em>Psychological Methods</em>, <em>16</em>(4), 406.</p>
</div>
<div id="ref-morey2014simple">
<p>Morey, R. D., &amp; Wagenmakers, E.-J. (2014). Simple relation between bayesian order-restricted and point-null hypothesis tests. <em>Statistics &amp; Probability Letters</em>, <em>92</em>, 121–124.</p>
</div>
<div id="ref-rouder2018bayesian">
<p>Rouder, J. N., Haaf, J. M., &amp; Vandekerckhove, J. (2018). Bayesian inference for psychology, part iv: Parameter estimation and bayes factors. <em>Psychonomic Bulletin &amp; Review</em>, <em>25</em>(1), 102–113.</p>
</div>
<div id="ref-rouder2012default">
<p>Rouder, J. N., Morey, R. D., Speckman, P. L., &amp; Province, J. M. (2012). Default bayes factors for anova designs. <em>Journal of Mathematical Psychology</em>, <em>56</em>(5), 356–374.</p>
</div>
<div id="ref-wagenmakers2007practical">
<p>Wagenmakers, E.-J. (2007). A practical solution to the pervasive problems ofp values. <em>Psychonomic Bulletin &amp; Review</em>, <em>14</em>(5), 779–804.</p>
</div>
<div id="ref-wagenmakers2018SI">
<p>Wagenmakers, E.-J., Gronau, Q. F., Dablander, F., &amp; Etz, A. (2018). <em>The support interval</em>. <a href="https://doi.org/10.31234/osf.io/zwnxb">https://doi.org/10.31234/osf.io/zwnxb</a></p>
</div>
<div id="ref-wagenmakers2010bayesian">
<p>Wagenmakers, E.-J., Lodewyckx, T., Kuriyal, H., &amp; Grasman, R. (2010). Bayesian hypothesis testing for psychologists: A tutorial on the savage–dickey method. <em>Cognitive Psychology</em>, <em>60</em>(3), 158–189.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr>
<ol>
<li id="fn1"><p>Note that as the width of null interval shrinks to zero, the prior probability and posterior probability of the alternative tends towards 1.00.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>For more, see <a href="https://philstatwars.files.wordpress.com/2020/09/richard_presentation.mp4">this talk by Richard D. Morey, minute 48</a><a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p><a href="https://doi.org/10.1016/j.jmp.2015.08.002">Robert, 2016</a>; <a href="https://doi.org/10.1080/01621459.1995.10476572">Kass &amp; Raftery, 1993</a>; <a href="https://doi.org/10.1016/S0304-4076(00)00076-2">Fernández, Ley, &amp; Steel, 2001</a><a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p><a href="https://arxiv.org/abs/1710.08162">Gronau, Singmann, &amp; Wagenmakers, 2017</a><a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>A model without predictor <span class="math inline">\(X\)</span> can be thought of as a model in which the parameter(s) of the predictor have been restricted to a null-point of 0.<a href="#fnref5" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by <a href="https://dominiquemakowski.github.io/">Dominique Makowski</a>, <a href="https://github.com/strengejacke">Daniel Lüdecke</a>, <a href="https://github.com/mattansb">Mattan S. Ben-Shachar</a>, <a href="http://www.humanfactors.io">Michael D. Wilson</a>.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
